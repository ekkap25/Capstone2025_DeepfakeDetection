{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzf8Nh17XgSdbaRSjPk6tf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Mount & install\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip -q install efficientnet tensorflow-addons\n","\n","# Reproducibility\n","import os, random, numpy as np, tensorflow as tf\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n","\n","#Common imports\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from efficientnet.tfkeras import EfficientNetB0\n","\n"],"metadata":{"id":"4iRsOAnQ1A2M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BASE = '/content/drive/MyDrive/Capstone2025_DeepfakeDetection'\n","DATA = f'{BASE}/data/frames_cropped_split'\n","MODEL_DIR = f'{BASE}/models_fast'\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","\n","IMG_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","EPOCHS = 15\n"],"metadata":{"id":"EuWV3SMR1CBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = datagen.flow_from_directory(\n","    os.path.join(DATA, 'train'), target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE, class_mode='binary', shuffle=True, seed=SEED\n",")\n","val_generator = datagen.flow_from_directory(\n","    os.path.join(DATA, 'val'), target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",")\n","test_generator = datagen.flow_from_directory(\n","    os.path.join(DATA, 'test'), target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",")\n","\n","# class weights\n","from collections import Counter\n","counts = Counter(train_generator.classes)  # {0: real, 1: fake}\n","total = sum(counts.values())\n","class_weight = {0: total/(2.0*counts[0]), 1: total/(2.0*counts[1])}\n","class_weight\n"],"metadata":{"id":"y9VG0iY81Es0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_head(base, dropout=0.3):\n","    x = layers.GlobalAveragePooling2D()(base.output)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.Dropout(dropout)(x)\n","    out = layers.Dense(1, activation='sigmoid')(x)\n","    return Model(base.input, out)\n","\n","def build_mobilenetv2(input_shape=(224,224,3)):\n","    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base.trainable = False   # keeping frozen\n","    model = add_head(base, dropout=0.3)\n","    model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def build_efficientnetb0(input_shape=(224,224,3)):\n","    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base.trainable = False   # keeping frozen\n","    model = add_head(base, dropout=0.3)\n","    model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","mnv2 = build_mobilenetv2()\n","enb0 = build_efficientnetb0()\n"],"metadata":{"id":"9SiHekLl1bK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_callbacks(name):\n","    return [\n","        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, min_lr=1e-6, verbose=1),\n","        ModelCheckpoint(os.path.join(MODEL_DIR, f'{name}_best.keras'),\n","                        monitor='val_accuracy', save_best_only=True, verbose=1)\n","    ]\n","\n","def plot_history(h, title):\n","    acc, val_acc = h.history['accuracy'], h.history['val_accuracy']\n","    loss, val_loss = h.history['loss'], h.history['val_loss']\n","    rng = range(len(acc))\n","    plt.figure(figsize=(12,4))\n","    plt.subplot(1,2,1); plt.plot(rng, acc, label='train'); plt.plot(rng, val_acc, label='val'); plt.title(f'{title} Acc'); plt.legend()\n","    plt.subplot(1,2,2); plt.plot(rng, loss, label='train'); plt.plot(rng, val_loss, label='val'); plt.title(f'{title} Loss'); plt.legend()\n","    plt.show()\n","\n","def train_one(model, name, epochs=EPOCHS):\n","    h = model.fit(\n","        train_generator,\n","        validation_data=val_generator,\n","        epochs=epochs,\n","        callbacks=get_callbacks(name),\n","        class_weight=class_weight,\n","        verbose=1\n","    )\n","    plot_history(h, name)\n","    return model\n"],"metadata":{"id":"zSbFsE1x1eFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Training MobileNetV2 (single-stage)...\")\n","mnv2 = train_one(mnv2, 'mobilenetv2_fast', epochs=EPOCHS)\n","\n","print(\"Training EfficientNetB0 (single-stage)...\")\n","enb0 = train_one(enb0, 'efficientnetb0_fast', epochs=EPOCHS)\n"],"metadata":{"id":"aRCiXn9G1fne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#weight sweep on VAL, evaluate on TEST\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n","\n","# 1) Load models\n","def _load_best(name_fast, name_ft):\n","    try:\n","        return load_model(f\"{MODEL_DIR}/{name_fast}.keras\")\n","    except Exception as _:\n","        return load_model(f\"{MODEL_DIR}/{name_ft}.keras\")\n","\n","mnv2_best = _load_best(\"mobilenetv2_fast_best\", \"mobilenetv2_ft_best\")\n","enb0_best = _load_best(\"efficientnetb0_fast_best\", \"efficientnetb0_ft_best\")\n","\n","# 2) Get VAL predictions\n","val_y      = val_generator.classes\n","val_mnv2_p = mnv2_best.predict(val_generator, verbose=1)\n","val_enb0_p = enb0_best.predict(val_generator, verbose=1)\n","\n","# 3) Sweep α on VAL (EfficientNetB0 weight = α, MobileNetV2 weight = 1-α)\n","alphas = np.linspace(0.0, 1.0, 21)  # 0.00, 0.05, ..., 1.00\n","\n","def pick_best_alpha(metric=\"f1\"):\n","    best_alpha, best_score = None, -1\n","    for a in alphas:\n","        probs = a*val_enb0_p + (1-a)*val_mnv2_p\n","        preds = (probs >= 0.5).astype(int)\n","        if metric == \"f1\":\n","            score = f1_score(val_y, preds, pos_label=1)\n","        else:\n","            score = accuracy_score(val_y, preds)\n","        if score > best_score:\n","            best_alpha, best_score = float(a), float(score)\n","    return best_alpha, best_score\n","\n","alpha_f1,  f1_best  = pick_best_alpha(metric=\"f1\")\n","alpha_acc, acc_best = pick_best_alpha(metric=\"acc\")\n","\n","print(f\"\\nBest α (by F1-Fake): {alpha_f1:.2f}  | F1={f1_best:.4f}\")\n","print(f\"Best α (by Accuracy): {alpha_acc:.2f} | Acc={acc_best:.4f}\")\n","\n","ALPHA = alpha_acc\n","print(f\"\\n>> Using α={ALPHA:.2f} for TEST (EfficientNetB0 weight).\")\n","\n","# 4) Optional threshold tuning on VAL for the chosen α (keeps default 0.5 if no gain)\n","def best_threshold(val_probs, y, metric_fn, sweep=np.linspace(0.3, 0.7, 17)):\n","    best_t, best_m = 0.5, -1\n","    for t in sweep:\n","        preds = (val_probs >= t).astype(int)\n","        m = metric_fn(y, preds)\n","        if m > best_m:\n","            best_t, best_m = float(t), float(m)\n","    return best_t, best_m\n","\n","val_probs_alpha = ALPHA*val_enb0_p + (1-ALPHA)*val_mnv2_p\n","t_opt, m_opt = best_threshold(val_probs_alpha, val_y, lambda y,p: accuracy_score(y,p))\n","print(f\"Val-tuned threshold (for accuracy): {t_opt:.2f} (val-acc={m_opt:.4f})\")\n","\n","# 5) TEST evaluation for (a) equal-weight 0.50 and (b) α-chosen + t_opt\n","test_y      = test_generator.classes\n","test_mnv2_p = mnv2_best.predict(test_generator, verbose=1)\n","test_enb0_p = enb0_best.predict(test_generator, verbose=1)\n","\n","# (i) Equal-weight baseline\n","test_probs_50 = 0.5*test_enb0_p + 0.5*test_mnv2_p\n","test_pred_50  = (test_probs_50 >= 0.5).astype(int)\n","acc_50 = accuracy_score(test_y, test_pred_50)\n","print(\"\\n=== Equal-weight (0.50/0.50), threshold=0.50 ===\")\n","print(\"Accuracy:\", acc_50)\n","print(classification_report(test_y, test_pred_50, target_names=['Real','Fake']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, test_pred_50))\n","\n","# (ii) Chosen α + tuned threshold\n","test_probs_a = ALPHA*test_enb0_p + (1-ALPHA)*test_mnv2_p\n","test_pred_a  = (test_probs_a >= t_opt).astype(int)\n","acc_a = accuracy_score(test_y, test_pred_a)\n","print(f\"\\n=== Weighted (α={ALPHA:.2f}), threshold={t_opt:.2f} ===\")\n","print(\"Accuracy:\", acc_a)\n","print(classification_report(test_y, test_pred_a, target_names=['Real','Fake']))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, test_pred_a))\n","\n","# 6) Saving the settings\n","import json, time\n","summary = {\n","    \"alpha_used\": ALPHA,\n","    \"threshold_used\": t_opt,\n","    \"val_best_alpha_acc\": {\"alpha\": alpha_acc, \"val_acc\": acc_best},\n","    \"val_best_alpha_f1\":  {\"alpha\": alpha_f1,  \"val_f1_fake\": f1_best},\n","    \"test_equal_weight_acc\": acc_50,\n","    \"test_weighted_acc\": acc_a,\n","    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n","}\n","with open(f\"{MODEL_DIR}/ensemble_summary.json\", \"w\") as f:\n","    json.dump(summary, f, indent=2)\n","print(f\"\\nSaved summary → {MODEL_DIR}/ensemble_summary.json\")\n"],"metadata":{"id":"NVS4-Ft3ZdSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load best checkpoints\n","from tensorflow.keras.models import load_model\n","import numpy as np, os, cv2, matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","mnv2 = load_model(os.path.join(MODEL_DIR, 'mobilenetv2_fast_best.keras'))\n","enb0 = load_model(os.path.join(MODEL_DIR, 'efficientnetb0_fast_best.keras'))\n","\n","\n","# Label names\n","idx_to_label = {v:k for k,v in test_generator.class_indices.items()}\n","\n","GC_DIR = os.path.join(MODEL_DIR, 'gradcam')\n","os.makedirs(GC_DIR, exist_ok=True)\n"],"metadata":{"id":"IhkZMFR-efif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_last_conv_layer(model):\n","    # Finding the last 2D conv-like layer\n","    for layer in reversed(model.layers):\n","        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.DepthwiseConv2D)):\n","            return layer.name\n","    # Fallback\n","    candidates = ['Conv_1', 'block7a_project_conv']\n","    for name in candidates:\n","        if name in [l.name for l in model.layers]:\n","            return name\n","    raise ValueError(\"No convolutional layer found for Grad-CAM.\")\n","\n","def compute_gradcam(model, img_array, layer_name=None, eps=1e-8):\n","    \"\"\"\n","    img_array: (H,W,3) in [0,1] (already rescaled). Will add batch dim inside.\n","    Returns heatmap in [0,1], same HxW.\n","    \"\"\"\n","    if layer_name is None:\n","        layer_name = get_last_conv_layer(model)\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs],\n","        [model.get_layer(layer_name).output, model.output]\n","    )\n","\n","    with tf.GradientTape() as tape:\n","        inputs = tf.cast(img_array[None, ...], tf.float32)\n","        conv_outputs, preds = grad_model(inputs)\n","        # Binary classifier - sigmoid output\n","        loss = preds[:, 0]\n","\n","    grads = tape.gradient(loss, conv_outputs)\n","    # Global-average-pool the gradients over spatial dims\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    conv_outputs = conv_outputs[0]\n","    heatmap = tf.reduce_sum(tf.multiply(conv_outputs, pooled_grads), axis=-1)\n","\n","    heatmap = tf.nn.relu(heatmap)\n","    heatmap = heatmap / (tf.reduce_max(heatmap) + eps)\n","    heatmap = heatmap.numpy()\n","    # Resize to input size\n","    h, w = img_array.shape[:2]\n","    heatmap = cv2.resize(heatmap, (w, h), interpolation=cv2.INTER_CUBIC)\n","    return heatmap\n","\n","def overlay_heatmap(img, heatmap, alpha=0.35):\n","    \"\"\"\n","    img: float [0,1], heatmap: [0,1], returns RGB [0,1]\n","    \"\"\"\n","    cmap = cv2.applyColorMap((heatmap*255).astype(np.uint8), cv2.COLORMAP_JET)\n","    cmap = cv2.cvtColor(cmap, cv2.COLOR_BGR2RGB) / 255.0\n","    overlay = (1 - alpha) * img + alpha * cmap\n","    overlay = np.clip(overlay, 0, 1)\n","    return overlay\n"],"metadata":{"id":"yrM-u1Rieht0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_prob(model, img):\n","\n","    p = model.predict(img[None, ...], verbose=0)[0,0]\n","    return float(p)\n","\n","def show_and_save_gradcam(img, label, fname_prefix=\"sample\"):\n","\n","    # Individual model CAMs\n","    cam_mnv2 = compute_gradcam(mnv2, img)\n","    cam_enb0 = compute_gradcam(enb0, img)\n","\n","    # average of normalized heatmaps\n","    cam_ens = (cam_mnv2 + cam_enb0) / 2.0\n","\n","    # overlays\n","    ov_mnv2 = overlay_heatmap(img, cam_mnv2)\n","    ov_enb0 = overlay_heatmap(img, cam_enb0)\n","    ov_ens  = overlay_heatmap(img, cam_ens)\n","\n","    # prredictions\n","    p_mnv2 = predict_prob(mnv2, img)\n","    p_enb0 = predict_prob(enb0, img)\n","    p_ens  = (p_mnv2 + p_enb0) / 2.0\n","\n","    # Titles\n","    gt = idx_to_label[int(label)]\n","    pred_m = f\"MobileNetV2: p(fake)={p_mnv2:.3f}\"\n","    pred_e = f\"EfficientNetB0: p(fake)={p_enb0:.3f}\"\n","    pred_s = f\"Ensemble: p(fake)={p_ens:.3f}\"\n","\n","    # Plot\n","    plt.figure(figsize=(12,9))\n","    plt.subplot(2,2,1); plt.imshow(img); plt.axis('off'); plt.title(f\"Original (GT: {gt})\")\n","    plt.subplot(2,2,2); plt.imshow(ov_mnv2); plt.axis('off'); plt.title(pred_m)\n","    plt.subplot(2,2,3); plt.imshow(ov_enb0); plt.axis('off'); plt.title(pred_e)\n","    plt.subplot(2,2,4); plt.imshow(ov_ens);  plt.axis('off'); plt.title(pred_s)\n","    plt.tight_layout()\n","\n","    # Save\n","    out_path = os.path.join(GC_DIR, f\"{fname_prefix}.png\")\n","    plt.savefig(out_path, dpi=150, bbox_inches='tight')\n","    plt.show()\n","    print(f\"Saved → {out_path}\")\n"],"metadata":{"id":"pFOkDMpOe3DP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reset generator\n","test_generator.reset()\n","\n","# select one batch from test set\n","batch_imgs, batch_labels = next(test_generator)  # shapes: (B,224,224,3), (B,)\n","\n","# Visualize first K samples in that batch\n","K = 5\n","for i in range(K):\n","    img = batch_imgs[i]\n","    lbl = batch_labels[i]\n","    show_and_save_gradcam(img, lbl, fname_prefix=f\"gradcam_test_{i}\")\n"],"metadata":{"id":"DM6ylZJYe9Zg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sG2-zuevIXhw"},"execution_count":null,"outputs":[]}]}